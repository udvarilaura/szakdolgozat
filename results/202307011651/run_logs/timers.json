{
    "name": "root",
    "gauges": {
        "camPlacerAgent.Policy.Entropy.mean": {
            "value": 2.220651865005493,
            "min": 2.220651865005493,
            "max": 3.097238540649414,
            "count": 8
        },
        "camPlacerAgent.Policy.Entropy.sum": {
            "value": 22206.51953125,
            "min": 22206.51953125,
            "max": 30972.384765625,
            "count": 8
        },
        "camPlacerAgent.Environment.EpisodeLength.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 8
        },
        "camPlacerAgent.Environment.EpisodeLength.sum": {
            "value": 5000.0,
            "min": 5000.0,
            "max": 5000.0,
            "count": 8
        },
        "camPlacerAgent.Step.mean": {
            "value": 79998.0,
            "min": 9998.0,
            "max": 79998.0,
            "count": 8
        },
        "camPlacerAgent.Step.sum": {
            "value": 79998.0,
            "min": 9998.0,
            "max": 79998.0,
            "count": 8
        },
        "camPlacerAgent.Policy.ExtrinsicValueEstimate.mean": {
            "value": -0.4981657862663269,
            "min": -0.49817803502082825,
            "max": -0.17652685940265656,
            "count": 8
        },
        "camPlacerAgent.Policy.ExtrinsicValueEstimate.sum": {
            "value": -2490.828857421875,
            "min": -2490.89013671875,
            "max": -882.457763671875,
            "count": 8
        },
        "camPlacerAgent.Environment.CumulativeReward.mean": {
            "value": -0.5,
            "min": -0.5,
            "max": -0.5,
            "count": 8
        },
        "camPlacerAgent.Environment.CumulativeReward.sum": {
            "value": -2500.0,
            "min": -2500.0,
            "max": -2499.5,
            "count": 8
        },
        "camPlacerAgent.Policy.ExtrinsicReward.mean": {
            "value": -0.5,
            "min": -0.5,
            "max": -0.5,
            "count": 8
        },
        "camPlacerAgent.Policy.ExtrinsicReward.sum": {
            "value": -2500.0,
            "min": -2500.0,
            "max": -2499.5,
            "count": 8
        },
        "camPlacerAgent.Losses.PolicyLoss.mean": {
            "value": 0.24954882755816743,
            "min": 0.24915212903104883,
            "max": 0.25590642471689784,
            "count": 8
        },
        "camPlacerAgent.Losses.PolicyLoss.sum": {
            "value": 2.4954882755816743,
            "min": 2.2782554396753905,
            "max": 2.5590642471689784,
            "count": 8
        },
        "camPlacerAgent.Losses.ValueLoss.mean": {
            "value": 1.7386533814260474e-05,
            "min": 1.7386533814260474e-05,
            "max": 0.006208781988735288,
            "count": 8
        },
        "camPlacerAgent.Losses.ValueLoss.sum": {
            "value": 0.00017386533814260473,
            "min": 0.00017386533814260473,
            "max": 0.055879037898617596,
            "count": 8
        },
        "camPlacerAgent.Policy.LearningRate.mean": {
            "value": 0.00025494241501919997,
            "min": 0.00025494241501919997,
            "max": 0.000296976001008,
            "count": 8
        },
        "camPlacerAgent.Policy.LearningRate.sum": {
            "value": 0.0025494241501919997,
            "min": 0.0025494241501919997,
            "max": 0.0029123040292319997,
            "count": 8
        },
        "camPlacerAgent.Policy.Epsilon.mean": {
            "value": 0.18498080000000003,
            "min": 0.18498080000000003,
            "max": 0.198992,
            "count": 8
        },
        "camPlacerAgent.Policy.Epsilon.sum": {
            "value": 1.8498080000000003,
            "min": 1.790928,
            "max": 1.970768,
            "count": 8
        },
        "camPlacerAgent.Policy.Beta.mean": {
            "value": 0.0005000000000000002,
            "min": 0.0005000000000000001,
            "max": 0.0005000000000000002,
            "count": 8
        },
        "camPlacerAgent.Policy.Beta.sum": {
            "value": 0.005000000000000002,
            "min": 0.004500000000000001,
            "max": 0.005000000000000002,
            "count": 8
        },
        "camPlacerAgent.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 8
        },
        "camPlacerAgent.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 8
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1688223077",
        "python_version": "3.7.13 (default, Oct 19 2022, 10:19:43) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\Szabolcs\\anaconda3\\envs\\env2\\Scripts\\mlagents-learn config/camPlacerAgent_config.yaml --run-id=202307011651",
        "mlagents_version": "0.28.0",
        "mlagents_envs_version": "0.28.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.13.1+cu117",
        "numpy_version": "1.21.6",
        "end_time_seconds": "1688223817"
    },
    "total": 740.2426243,
    "count": 1,
    "self": 0.00474860000008448,
    "children": {
        "run_training.setup": {
            "total": 0.07935829999999999,
            "count": 1,
            "self": 0.07935829999999999
        },
        "TrainerController.start_learning": {
            "total": 740.1585173999999,
            "count": 1,
            "self": 0.20854939999856015,
            "children": {
                "TrainerController._reset_env": {
                    "total": 56.9086025,
                    "count": 1,
                    "self": 56.9086025
                },
                "TrainerController.advance": {
                    "total": 682.9427452000015,
                    "count": 10710,
                    "self": 0.2101464000006672,
                    "children": {
                        "env_step": {
                            "total": 251.2938667000005,
                            "count": 10710,
                            "self": 227.51241630000277,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 23.666904400000206,
                                    "count": 10710,
                                    "self": 0.47659159999680867,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 23.190312800003397,
                                            "count": 10710,
                                            "self": 10.292614100007697,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 12.8976986999957,
                                                    "count": 10710,
                                                    "self": 12.8976986999957
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.11454599999753867,
                                    "count": 10710,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 684.1072249000053,
                                            "count": 10710,
                                            "is_parallel": true,
                                            "self": 467.93698740000514,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.00041840000000092914,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00021139999999775227,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.00020700000000317686,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.00020700000000317686
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 216.16981910000024,
                                                    "count": 10710,
                                                    "is_parallel": true,
                                                    "self": 1.2765995999926076,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 1.258788299998642,
                                                            "count": 10710,
                                                            "is_parallel": true,
                                                            "self": 1.258788299998642
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 209.65078910000895,
                                                            "count": 10710,
                                                            "is_parallel": true,
                                                            "self": 209.65078910000895
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 3.983642100000033,
                                                            "count": 10710,
                                                            "is_parallel": true,
                                                            "self": 1.9079797999940027,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 2.07566230000603,
                                                                    "count": 21420,
                                                                    "is_parallel": true,
                                                                    "self": 2.07566230000603
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 431.4387321000003,
                            "count": 10710,
                            "self": 0.21261089999848082,
                            "children": {
                                "process_trajectory": {
                                    "total": 68.3281340000018,
                                    "count": 10710,
                                    "self": 68.3281340000018
                                },
                                "_update_policy": {
                                    "total": 362.89798720000005,
                                    "count": 85,
                                    "self": 20.620888799998397,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 342.27709840000165,
                                            "count": 50793,
                                            "self": 342.27709840000165
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 1.3999999737279722e-06,
                    "count": 1,
                    "self": 1.3999999737279722e-06
                },
                "TrainerController._save_models": {
                    "total": 0.0986188999999058,
                    "count": 1,
                    "self": 0.0011956999999256368,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.09742319999998017,
                            "count": 1,
                            "self": 0.09742319999998017
                        }
                    }
                }
            }
        }
    }
}